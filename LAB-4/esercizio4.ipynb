{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si richiede un'implementazione di un metodo per la generazione di una nuova lingua (che chiameremo NL). In particolare, partendo da una lingua di partenza L1 (ad es. la lingua Inglese), si prendano i termini di L1 usando un dizionario elettronico (ad es. WordNet o BabelNet). Per ogni termine t ed i suoi sensi S_t, dovrete cercare un nuovo termine tt (in una seconda lingua L2 a vostra scelta) da accoppiare a t, per la costruzione del termine t-tt, da inserire in NL. Il termine tt in L2 va selezionato tra quelli meno ambigui per il concetto S_t di riferimento. Si richiede di calcolare un valore di riduzione dell'ambiguità della nuova lingua rispetto a quella di partenza (ad es. calcolando il numero di sensi associabili ai termini t-tt in NL rispetto a quelli associabili ai termini t in L1. Una volta implementato il sistema, potrete cambiare la lingua L2 per valutare il potere \"disambiguante\" di diverse lingue rispetto a quella di partenza L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raccolta insieme di termini t di L1 (Inglese) da WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rossellaborra/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def get_random_words_from_wordnet(num_words):\n",
    "    all_synsets = list(wordnet.all_synsets())\n",
    "    random_words = []\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        random_synset = random.choice(all_synsets)\n",
    "        random_word = random_synset.lemmas()[0].name()\n",
    "        while len(wordnet.synsets(random_word ,lang=\"ita\")) == 0:\n",
    "                random_synset = random.choice(all_synsets)\n",
    "                random_word = random_synset.lemmas()[0].name()\n",
    "                \n",
    "        random_words.append(random_word)\n",
    "\n",
    "    return random_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ricerca synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_synsets(t_words):\n",
    "    S_t= {}\n",
    "    for word in t_words:\n",
    "        syn= wordnet.synsets(word)\n",
    "        S_t[word]= syn\n",
    "    return S_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pH_scale-pH --->  []\n",
      "raid-lira --->  []\n",
      "drive-parabola --->  []\n",
      "Maltese_lira-magnum --->  []\n",
      "surcharge-bandire --->  []\n",
      "parabola-Angola --->  []\n",
      "papillon-sol --->  []\n",
      "magnum-bei --->  []\n",
      "revenant-Guiana --->  []\n",
      "pengo-flamenco --->  []\n",
      "stigma-cavallo_di_posta --->  []\n",
      "sink-sarong --->  []\n",
      "big-diploma --->  []\n",
      "monitor-arrendersi --->  []\n",
      "ban-castrato --->  []\n",
      "Republic_of_Angola-ributtare --->  []\n",
      "gentile-amide --->  []\n",
      "rand-maltese --->  []\n",
      "colloidal_suspension-GAP! --->  []\n",
      "hostess-sbarrare --->  []\n",
      "bey-Nigeria --->  []\n",
      "sandwich-Albania --->  []\n",
      "Guiana-metropolitana --->  []\n",
      "flamenco-acaro --->  []\n",
      "poster-task_force --->  []\n",
      "sarong-canestro --->  []\n",
      "Prima-unità_centrale_di_elaborazione --->  []\n",
      "Sikh-receptionist --->  []\n",
      "picnic-videoscrittura --->  []\n",
      "geyser-torre_campanaria --->  []\n",
      "sheepskin-recinto_degli_animali --->  []\n",
      "bang-apache --->  []\n",
      "bunker-betel --->  []\n",
      "export-colonnista --->  []\n",
      "standard-Botswana --->  []\n",
      "yield-indirizzare --->  []\n",
      "castrato-GAP! --->  []\n",
      "cap-Okapia_johnstoni --->  []\n",
      "cast-America --->  []\n",
      "amide-Lesotho --->  []\n",
      "clinch-acetone --->  []\n",
      "Principe-solo --->  []\n",
      "Maltese-area --->  []\n",
      "quarterback-portico --->  []\n",
      "bar-autocaravan --->  []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_random_words = 100\n",
    "t_words = get_random_words_from_wordnet(num_random_words)\n",
    "S_t = search_synsets(t_words) \n",
    "source_language = \"eng\"\n",
    "target_language = \"ita\"\n",
    "\n",
    "S_t_best_senses,S_t_best_lemma = select_less_ambiguous_sense(S_t)\n",
    "\n",
    "tt_word = search_l2_words(target_language,S_t_best_senses,S_t_best_lemma )\n",
    "\n",
    "for key in tt_word.keys():\n",
    "    s = key+\"-\"+tt_word[key]\n",
    "    print(s, \"---> \", wordnet.synsets(s))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_l2_words(target_language,S_t_best_senses,S_t_best_lemma):\n",
    "    tt_words= {}\n",
    "    count=0\n",
    "    \n",
    "    for key in S_t_best_senses:\n",
    "        \n",
    "        tt_w = key.lemmas(lang=target_language)\n",
    "        k_list= list(S_t_best_lemma.keys())\n",
    "        if len(tt_w) != 0:\n",
    "            tt_words[S_t_best_lemma[k_list[count]]] = tt_w[0].name()\n",
    "        count=count+1\n",
    "    return tt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_less_ambiguous_sense(S_t):\n",
    "    \n",
    "    S_t_best_sense= {}\n",
    "    S_t_best_lemma = {}\n",
    "    lemmas_l1 = []\n",
    "    lemmas_l1_name = []\n",
    "    \n",
    "  \n",
    "    for key in S_t.keys():\n",
    "        best_sense_l1 = None\n",
    "        max_frequency = 0\n",
    "        frequency = 0\n",
    "     \n",
    "        for sense in S_t[key]:\n",
    "            lemmas= sense.lemmas(lang='eng')\n",
    "        \n",
    "        #creo lista di lemmi da confrontare frequenza \n",
    "            for l in lemmas:\n",
    "                lemmas_l1.append(l)\n",
    "                lemmas_l1_name.append(l.name())\n",
    "            \n",
    "    \n",
    "            for lemma_l1 in lemmas_l1:\n",
    "                lemma_name= l.name()\n",
    "                \n",
    "        #prendo lemma con frequenza maggiore tra i sensi\n",
    "            frequency = lemmas_l1_name.count(lemma_name)\n",
    "            if frequency > max_frequency:\n",
    "                max_frequency = frequency\n",
    "                best_sense_l1 = lemma_name\n",
    "                    \n",
    "                    \n",
    "        S_t_best_sense[sense] = best_sense_l1\n",
    "        S_t_best_lemma[lemma_name] = best_sense_l1\n",
    "  \n",
    "    return  S_t_best_sense,S_t_best_lemma\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduzione inglese: dog\n",
      "Traduzione inglese: domestic_dog\n",
      "Traduzione inglese: Canis_familiaris\n",
      "Traduzione inglese: cramp\n",
      "Traduzione inglese: hammer\n",
      "Traduzione inglese: cock\n",
      "Traduzione inglese: bad_person\n",
      "Traduzione inglese: incompetent\n",
      "Traduzione inglese: incompetent_person\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "parola_italiana = \"cane\"\n",
    "sinonimi_italiani = wordnet.synsets(parola_italiana, lang='ita')\n",
    "for senso_italiano in sinonimi_italiani:\n",
    "    corrispondenze_inglese = senso_italiano.lemmas(lang='eng')\n",
    "    for lemma in corrispondenze_inglese:\n",
    "        print(\"Traduzione inglese:\", lemma.name())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
